# Deep_Learning_Practicals

Welcome to this repository, your hub for exploring various deep learning concepts through practical experiments! Here, you'll find implementations and documentation for a wide range of algorithms, from fundamental building blocks to complex architectures.

# What's inside?

This repository is a living testament to your deep learning journey, containing practical implementations of diverse algorithms:

# Fundamentals:
  - DL MPneuron Perceptron: Explore the basic unit of neural networks,
   the perceptron, with code for both single and multi-layer implementations.
   
  - Sigmoid Activation: Understand and implement the sigmoid activation function, 
   a key component in building non-linear relationships.
   
  - Multiclass Neural Network: Dive into classifying multiple categories with a multiclass neural network, 
   tackling the challenges of one-hot encoding and softmax activation.


# Optimization Techniques:
  - Linear Regression with SGD: Implement linear regression using Stochastic Gradient Descent (SGD),
    understanding the iterative learning process.
    
  - Mini-Batch Gradient Descent: Discover how mini-batch SGD improves efficiency by optimizing over smaller batches of data.

  - Optimization Techniques: Experiment with various optimization algorithms like momentum, Adam, and RMSprop, analyzing their impact on convergence and performance.
